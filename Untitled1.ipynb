{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47dc980d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /opt/anaconda3/lib/python3.9/site-packages (1.6.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (2.2.2)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (0.14.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (1.21.5)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (63.4.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/lib/python3.9/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging>17.1->torchmetrics) (3.0.9)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->torchmetrics) (3.6.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->torchmetrics) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->torchmetrics) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->torchmetrics) (2.11.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->torchmetrics) (2022.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=2.0.0->torchmetrics) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d3b334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 20000\n",
      "Labels for first few samples: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch [1/5], Step [10/625], Loss: 1.8624\n",
      "Epoch [1/5], Step [20/625], Loss: 1.4224\n",
      "Epoch [1/5], Step [30/625], Loss: 1.3969\n",
      "Epoch [1/5], Step [40/625], Loss: 1.3771\n",
      "Epoch [1/5], Step [50/625], Loss: 1.3786\n",
      "Epoch [1/5], Step [60/625], Loss: 1.3820\n",
      "Epoch [1/5], Step [70/625], Loss: 1.3977\n",
      "Epoch [1/5], Step [80/625], Loss: 1.4313\n",
      "Epoch [1/5], Step [90/625], Loss: 1.3699\n",
      "Epoch [1/5], Step [100/625], Loss: 1.3918\n",
      "Epoch [1/5], Step [110/625], Loss: 1.4000\n",
      "Epoch [1/5], Step [120/625], Loss: 1.3907\n",
      "Epoch [1/5], Step [130/625], Loss: 1.4315\n",
      "Epoch [1/5], Step [140/625], Loss: 1.3962\n",
      "Epoch [1/5], Step [150/625], Loss: 1.3905\n",
      "Epoch [1/5], Step [160/625], Loss: 1.3971\n",
      "Epoch [1/5], Step [170/625], Loss: 1.3841\n",
      "Epoch [1/5], Step [180/625], Loss: 1.3780\n",
      "Epoch [1/5], Step [190/625], Loss: 1.3931\n",
      "Epoch [1/5], Step [200/625], Loss: 1.4128\n",
      "Epoch [1/5], Step [210/625], Loss: 1.3808\n",
      "Epoch [1/5], Step [220/625], Loss: 1.3759\n",
      "Epoch [1/5], Step [230/625], Loss: 1.4186\n",
      "Epoch [1/5], Step [240/625], Loss: 1.3842\n",
      "Epoch [1/5], Step [250/625], Loss: 1.3899\n",
      "Epoch [1/5], Step [260/625], Loss: 1.3592\n",
      "Epoch [1/5], Step [270/625], Loss: 1.3953\n",
      "Epoch [1/5], Step [280/625], Loss: 1.3888\n",
      "Epoch [1/5], Step [290/625], Loss: 1.4242\n",
      "Epoch [1/5], Step [300/625], Loss: 1.3916\n",
      "Epoch [1/5], Step [310/625], Loss: 1.3785\n",
      "Epoch [1/5], Step [320/625], Loss: 1.3839\n",
      "Epoch [1/5], Step [330/625], Loss: 1.3768\n",
      "Epoch [1/5], Step [340/625], Loss: 1.3878\n",
      "Epoch [1/5], Step [350/625], Loss: 1.3716\n",
      "Epoch [1/5], Step [360/625], Loss: 1.3826\n",
      "Epoch [1/5], Step [370/625], Loss: 1.4010\n",
      "Epoch [1/5], Step [380/625], Loss: 1.3653\n",
      "Epoch [1/5], Step [390/625], Loss: 1.3508\n",
      "Epoch [1/5], Step [400/625], Loss: 1.3772\n",
      "Epoch [1/5], Step [410/625], Loss: 1.4295\n",
      "Epoch [1/5], Step [420/625], Loss: 1.4067\n",
      "Epoch [1/5], Step [430/625], Loss: 1.3694\n",
      "Epoch [1/5], Step [440/625], Loss: 1.4121\n",
      "Epoch [1/5], Step [450/625], Loss: 1.3975\n",
      "Epoch [1/5], Step [460/625], Loss: 1.3817\n",
      "Epoch [1/5], Step [470/625], Loss: 1.3552\n",
      "Epoch [1/5], Step [480/625], Loss: 1.3969\n",
      "Epoch [1/5], Step [490/625], Loss: 1.4058\n",
      "Epoch [1/5], Step [500/625], Loss: 1.3928\n",
      "Epoch [1/5], Step [510/625], Loss: 1.3908\n",
      "Epoch [1/5], Step [520/625], Loss: 1.3671\n",
      "Epoch [1/5], Step [530/625], Loss: 1.3857\n",
      "Epoch [1/5], Step [540/625], Loss: 1.3776\n",
      "Epoch [1/5], Step [550/625], Loss: 1.3875\n",
      "Epoch [1/5], Step [560/625], Loss: 1.4024\n",
      "Epoch [1/5], Step [570/625], Loss: 1.3383\n",
      "Epoch [1/5], Step [580/625], Loss: 1.3829\n",
      "Epoch [1/5], Step [590/625], Loss: 1.4162\n",
      "Epoch [1/5], Step [600/625], Loss: 1.3605\n",
      "Epoch [1/5], Step [610/625], Loss: 1.3791\n",
      "Epoch [1/5], Step [620/625], Loss: 1.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 1.4031, Accuracy: 0.2650\n",
      "Class 0: Precision = 0.2718, Recall = 0.2960, F1 Score = 0.2834\n",
      "Class 1: Precision = 0.2576, Recall = 0.2726, F1 Score = 0.2649\n",
      "Class 2: Precision = 0.2635, Recall = 0.2290, F1 Score = 0.2450\n",
      "Class 3: Precision = 0.2693, Recall = 0.2622, F1 Score = 0.2657\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [2/5], Step [10/625], Loss: 1.3845\n",
      "Epoch [2/5], Step [20/625], Loss: 1.3797\n",
      "Epoch [2/5], Step [30/625], Loss: 1.3841\n",
      "Epoch [2/5], Step [40/625], Loss: 1.3852\n",
      "Epoch [2/5], Step [50/625], Loss: 1.3759\n",
      "Epoch [2/5], Step [60/625], Loss: 1.4825\n",
      "Epoch [2/5], Step [70/625], Loss: 1.3873\n",
      "Epoch [2/5], Step [80/625], Loss: 1.3801\n",
      "Epoch [2/5], Step [90/625], Loss: 1.3883\n",
      "Epoch [2/5], Step [100/625], Loss: 1.4287\n",
      "Epoch [2/5], Step [110/625], Loss: 1.3713\n",
      "Epoch [2/5], Step [120/625], Loss: 1.3703\n",
      "Epoch [2/5], Step [130/625], Loss: 1.4005\n",
      "Epoch [2/5], Step [140/625], Loss: 1.3650\n",
      "Epoch [2/5], Step [150/625], Loss: 1.2845\n",
      "Epoch [2/5], Step [160/625], Loss: 1.3991\n",
      "Epoch [2/5], Step [170/625], Loss: 1.4268\n",
      "Epoch [2/5], Step [180/625], Loss: 1.3922\n",
      "Epoch [2/5], Step [190/625], Loss: 1.3844\n",
      "Epoch [2/5], Step [200/625], Loss: 1.3781\n",
      "Epoch [2/5], Step [210/625], Loss: 1.3739\n",
      "Epoch [2/5], Step [220/625], Loss: 1.3915\n",
      "Epoch [2/5], Step [230/625], Loss: 1.3553\n",
      "Epoch [2/5], Step [240/625], Loss: 1.3166\n",
      "Epoch [2/5], Step [250/625], Loss: 1.2350\n",
      "Epoch [2/5], Step [260/625], Loss: 1.1777\n",
      "Epoch [2/5], Step [270/625], Loss: 1.3265\n",
      "Epoch [2/5], Step [280/625], Loss: 1.2366\n",
      "Epoch [2/5], Step [290/625], Loss: 1.1524\n",
      "Epoch [2/5], Step [300/625], Loss: 1.3449\n",
      "Epoch [2/5], Step [310/625], Loss: 1.4650\n",
      "Epoch [2/5], Step [320/625], Loss: 1.1976\n",
      "Epoch [2/5], Step [330/625], Loss: 1.3550\n",
      "Epoch [2/5], Step [340/625], Loss: 1.3449\n",
      "Epoch [2/5], Step [350/625], Loss: 1.3227\n",
      "Epoch [2/5], Step [360/625], Loss: 1.3785\n",
      "Epoch [2/5], Step [370/625], Loss: 1.3481\n",
      "Epoch [2/5], Step [380/625], Loss: 1.3776\n",
      "Epoch [2/5], Step [390/625], Loss: 1.3583\n",
      "Epoch [2/5], Step [400/625], Loss: 1.2840\n",
      "Epoch [2/5], Step [410/625], Loss: 1.3683\n",
      "Epoch [2/5], Step [420/625], Loss: 1.3825\n",
      "Epoch [2/5], Step [430/625], Loss: 1.3439\n",
      "Epoch [2/5], Step [440/625], Loss: 1.3629\n",
      "Epoch [2/5], Step [450/625], Loss: 1.3811\n",
      "Epoch [2/5], Step [460/625], Loss: 1.3678\n",
      "Epoch [2/5], Step [470/625], Loss: 1.3337\n",
      "Epoch [2/5], Step [480/625], Loss: 1.2976\n",
      "Epoch [2/5], Step [490/625], Loss: 1.2157\n",
      "Epoch [2/5], Step [500/625], Loss: 1.2737\n",
      "Epoch [2/5], Step [510/625], Loss: 1.1840\n",
      "Epoch [2/5], Step [520/625], Loss: 1.2671\n",
      "Epoch [2/5], Step [530/625], Loss: 1.1863\n",
      "Epoch [2/5], Step [540/625], Loss: 1.5085\n",
      "Epoch [2/5], Step [550/625], Loss: 1.3665\n",
      "Epoch [2/5], Step [560/625], Loss: 1.3624\n",
      "Epoch [2/5], Step [570/625], Loss: 1.3358\n",
      "Epoch [2/5], Step [580/625], Loss: 1.3506\n",
      "Epoch [2/5], Step [590/625], Loss: 1.3399\n",
      "Epoch [2/5], Step [600/625], Loss: 1.2959\n",
      "Epoch [2/5], Step [610/625], Loss: 1.1379\n",
      "Epoch [2/5], Step [620/625], Loss: 1.4429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 1.3520, Accuracy: 0.3257\n",
      "Class 0: Precision = 0.3681, Recall = 0.4486, F1 Score = 0.4044\n",
      "Class 1: Precision = 0.2762, Recall = 0.2138, F1 Score = 0.2410\n",
      "Class 2: Precision = 0.2787, Recall = 0.1966, F1 Score = 0.2306\n",
      "Class 3: Precision = 0.3411, Recall = 0.4440, F1 Score = 0.3858\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [3/5], Step [10/625], Loss: 1.3993\n",
      "Epoch [3/5], Step [20/625], Loss: 1.3849\n",
      "Epoch [3/5], Step [30/625], Loss: 1.3604\n",
      "Epoch [3/5], Step [40/625], Loss: 1.3229\n",
      "Epoch [3/5], Step [50/625], Loss: 1.3271\n",
      "Epoch [3/5], Step [60/625], Loss: 1.2253\n",
      "Epoch [3/5], Step [70/625], Loss: 1.1174\n",
      "Epoch [3/5], Step [80/625], Loss: 1.1773\n",
      "Epoch [3/5], Step [90/625], Loss: 1.8519\n",
      "Epoch [3/5], Step [100/625], Loss: 1.5562\n",
      "Epoch [3/5], Step [110/625], Loss: 1.4427\n",
      "Epoch [3/5], Step [120/625], Loss: 1.4466\n",
      "Epoch [3/5], Step [130/625], Loss: 1.3788\n",
      "Epoch [3/5], Step [140/625], Loss: 1.3749\n",
      "Epoch [3/5], Step [150/625], Loss: 1.3326\n",
      "Epoch [3/5], Step [160/625], Loss: 1.2365\n",
      "Epoch [3/5], Step [170/625], Loss: 1.3406\n",
      "Epoch [3/5], Step [180/625], Loss: 1.3160\n",
      "Epoch [3/5], Step [190/625], Loss: 1.2640\n",
      "Epoch [3/5], Step [200/625], Loss: 1.2744\n",
      "Epoch [3/5], Step [210/625], Loss: 1.2893\n",
      "Epoch [3/5], Step [220/625], Loss: 1.3376\n",
      "Epoch [3/5], Step [230/625], Loss: 1.2637\n",
      "Epoch [3/5], Step [240/625], Loss: 1.3708\n",
      "Epoch [3/5], Step [250/625], Loss: 1.3264\n",
      "Epoch [3/5], Step [260/625], Loss: 1.3543\n",
      "Epoch [3/5], Step [270/625], Loss: 1.3159\n",
      "Epoch [3/5], Step [280/625], Loss: 1.1852\n",
      "Epoch [3/5], Step [290/625], Loss: 1.2338\n",
      "Epoch [3/5], Step [300/625], Loss: 1.2879\n",
      "Epoch [3/5], Step [310/625], Loss: 1.1498\n",
      "Epoch [3/5], Step [320/625], Loss: 0.9805\n",
      "Epoch [3/5], Step [330/625], Loss: 1.5289\n",
      "Epoch [3/5], Step [340/625], Loss: 1.6019\n",
      "Epoch [3/5], Step [350/625], Loss: 1.4000\n",
      "Epoch [3/5], Step [360/625], Loss: 1.2815\n",
      "Epoch [3/5], Step [370/625], Loss: 1.3264\n",
      "Epoch [3/5], Step [380/625], Loss: 1.3655\n",
      "Epoch [3/5], Step [390/625], Loss: 1.3111\n",
      "Epoch [3/5], Step [400/625], Loss: 1.0648\n",
      "Epoch [3/5], Step [410/625], Loss: 0.9407\n",
      "Epoch [3/5], Step [420/625], Loss: 1.2163\n",
      "Epoch [3/5], Step [430/625], Loss: 1.0725\n",
      "Epoch [3/5], Step [440/625], Loss: 1.0313\n",
      "Epoch [3/5], Step [450/625], Loss: 1.0741\n",
      "Epoch [3/5], Step [460/625], Loss: 0.9599\n",
      "Epoch [3/5], Step [470/625], Loss: 0.9741\n",
      "Epoch [3/5], Step [480/625], Loss: 1.2483\n",
      "Epoch [3/5], Step [490/625], Loss: 0.9598\n",
      "Epoch [3/5], Step [500/625], Loss: 0.6230\n",
      "Epoch [3/5], Step [510/625], Loss: 0.7964\n",
      "Epoch [3/5], Step [520/625], Loss: 1.6995\n",
      "Epoch [3/5], Step [530/625], Loss: 0.8924\n",
      "Epoch [3/5], Step [540/625], Loss: 0.7481\n",
      "Epoch [3/5], Step [550/625], Loss: 1.0042\n",
      "Epoch [3/5], Step [560/625], Loss: 0.7009\n",
      "Epoch [3/5], Step [570/625], Loss: 0.7466\n",
      "Epoch [3/5], Step [580/625], Loss: 0.8606\n",
      "Epoch [3/5], Step [590/625], Loss: 1.3439\n",
      "Epoch [3/5], Step [600/625], Loss: 1.0308\n",
      "Epoch [3/5], Step [610/625], Loss: 0.8715\n",
      "Epoch [3/5], Step [620/625], Loss: 0.7707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 1.2029, Accuracy: 0.4314\n",
      "Class 0: Precision = 0.5295, Recall = 0.6708, F1 Score = 0.5918\n",
      "Class 1: Precision = 0.3617, Recall = 0.2390, F1 Score = 0.2878\n",
      "Class 2: Precision = 0.3472, Recall = 0.1952, F1 Score = 0.2499\n",
      "Class 3: Precision = 0.4109, Recall = 0.6206, F1 Score = 0.4945\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [4/5], Step [10/625], Loss: 0.7601\n",
      "Epoch [4/5], Step [20/625], Loss: 0.7362\n",
      "Epoch [4/5], Step [30/625], Loss: 0.9088\n",
      "Epoch [4/5], Step [40/625], Loss: 0.7651\n",
      "Epoch [4/5], Step [50/625], Loss: 0.7135\n",
      "Epoch [4/5], Step [60/625], Loss: 1.5295\n",
      "Epoch [4/5], Step [70/625], Loss: 1.0029\n",
      "Epoch [4/5], Step [80/625], Loss: 1.0986\n",
      "Epoch [4/5], Step [90/625], Loss: 0.8735\n",
      "Epoch [4/5], Step [100/625], Loss: 0.7360\n",
      "Epoch [4/5], Step [110/625], Loss: 0.7729\n",
      "Epoch [4/5], Step [120/625], Loss: 0.7844\n",
      "Epoch [4/5], Step [130/625], Loss: 0.6973\n",
      "Epoch [4/5], Step [140/625], Loss: 1.0158\n",
      "Epoch [4/5], Step [150/625], Loss: 0.8760\n",
      "Epoch [4/5], Step [160/625], Loss: 0.7754\n",
      "Epoch [4/5], Step [170/625], Loss: 0.8635\n",
      "Epoch [4/5], Step [180/625], Loss: 1.5318\n",
      "Epoch [4/5], Step [190/625], Loss: 1.5139\n",
      "Epoch [4/5], Step [200/625], Loss: 1.4077\n",
      "Epoch [4/5], Step [210/625], Loss: 1.2871\n",
      "Epoch [4/5], Step [220/625], Loss: 1.2391\n",
      "Epoch [4/5], Step [230/625], Loss: 1.1274\n",
      "Epoch [4/5], Step [240/625], Loss: 1.1107\n",
      "Epoch [4/5], Step [250/625], Loss: 0.9667\n",
      "Epoch [4/5], Step [260/625], Loss: 1.0202\n",
      "Epoch [4/5], Step [270/625], Loss: 1.0229\n",
      "Epoch [4/5], Step [280/625], Loss: 1.0078\n",
      "Epoch [4/5], Step [290/625], Loss: 0.9271\n",
      "Epoch [4/5], Step [300/625], Loss: 1.0178\n",
      "Epoch [4/5], Step [310/625], Loss: 1.0370\n",
      "Epoch [4/5], Step [320/625], Loss: 1.0320\n",
      "Epoch [4/5], Step [330/625], Loss: 0.8551\n",
      "Epoch [4/5], Step [340/625], Loss: 0.9349\n",
      "Epoch [4/5], Step [350/625], Loss: 0.8533\n",
      "Epoch [4/5], Step [360/625], Loss: 0.9667\n",
      "Epoch [4/5], Step [370/625], Loss: 0.8283\n",
      "Epoch [4/5], Step [380/625], Loss: 1.7016\n",
      "Epoch [4/5], Step [390/625], Loss: 1.5744\n",
      "Epoch [4/5], Step [400/625], Loss: 1.4420\n",
      "Epoch [4/5], Step [410/625], Loss: 1.3155\n",
      "Epoch [4/5], Step [420/625], Loss: 1.2905\n",
      "Epoch [4/5], Step [430/625], Loss: 1.2924\n",
      "Epoch [4/5], Step [440/625], Loss: 1.3092\n",
      "Epoch [4/5], Step [450/625], Loss: 1.3256\n",
      "Epoch [4/5], Step [460/625], Loss: 1.3394\n",
      "Epoch [4/5], Step [470/625], Loss: 1.3297\n",
      "Epoch [4/5], Step [480/625], Loss: 1.3157\n",
      "Epoch [4/5], Step [490/625], Loss: 1.2414\n",
      "Epoch [4/5], Step [500/625], Loss: 1.2377\n",
      "Epoch [4/5], Step [510/625], Loss: 1.2944\n",
      "Epoch [4/5], Step [520/625], Loss: 1.2842\n",
      "Epoch [4/5], Step [530/625], Loss: 1.3463\n",
      "Epoch [4/5], Step [540/625], Loss: 1.1719\n",
      "Epoch [4/5], Step [550/625], Loss: 1.0381\n",
      "Epoch [4/5], Step [560/625], Loss: 1.0167\n",
      "Epoch [4/5], Step [570/625], Loss: 1.0618\n",
      "Epoch [4/5], Step [580/625], Loss: 1.0597\n",
      "Epoch [4/5], Step [590/625], Loss: 1.2735\n",
      "Epoch [4/5], Step [600/625], Loss: 0.9413\n",
      "Epoch [4/5], Step [610/625], Loss: 1.4083\n",
      "Epoch [4/5], Step [620/625], Loss: 1.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 1.1166, Accuracy: 0.4774\n",
      "Class 0: Precision = 0.6215, Recall = 0.6706, F1 Score = 0.6451\n",
      "Class 1: Precision = 0.4239, Recall = 0.3340, F1 Score = 0.3736\n",
      "Class 2: Precision = 0.3434, Recall = 0.2448, F1 Score = 0.2858\n",
      "Class 3: Precision = 0.4650, Recall = 0.6604, F1 Score = 0.5457\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [5/5], Step [10/625], Loss: 1.2175\n",
      "Epoch [5/5], Step [20/625], Loss: 1.1890\n",
      "Epoch [5/5], Step [30/625], Loss: 1.0998\n",
      "Epoch [5/5], Step [40/625], Loss: 0.9493\n",
      "Epoch [5/5], Step [50/625], Loss: 0.9022\n",
      "Epoch [5/5], Step [60/625], Loss: 1.0677\n",
      "Epoch [5/5], Step [70/625], Loss: 0.9503\n",
      "Epoch [5/5], Step [80/625], Loss: 0.8342\n",
      "Epoch [5/5], Step [90/625], Loss: 0.8470\n",
      "Epoch [5/5], Step [100/625], Loss: 1.0873\n",
      "Epoch [5/5], Step [110/625], Loss: 1.4140\n",
      "Epoch [5/5], Step [120/625], Loss: 1.2951\n",
      "Epoch [5/5], Step [130/625], Loss: 1.1467\n",
      "Epoch [5/5], Step [140/625], Loss: 1.1196\n",
      "Epoch [5/5], Step [150/625], Loss: 1.0414\n",
      "Epoch [5/5], Step [160/625], Loss: 1.0123\n",
      "Epoch [5/5], Step [170/625], Loss: 0.7358\n",
      "Epoch [5/5], Step [180/625], Loss: 1.1375\n",
      "Epoch [5/5], Step [190/625], Loss: 1.0255\n",
      "Epoch [5/5], Step [200/625], Loss: 0.8212\n",
      "Epoch [5/5], Step [210/625], Loss: 0.8068\n",
      "Epoch [5/5], Step [220/625], Loss: 1.0397\n",
      "Epoch [5/5], Step [230/625], Loss: 0.9495\n",
      "Epoch [5/5], Step [240/625], Loss: 0.9809\n",
      "Epoch [5/5], Step [250/625], Loss: 0.9017\n",
      "Epoch [5/5], Step [260/625], Loss: 0.7749\n",
      "Epoch [5/5], Step [270/625], Loss: 0.6853\n",
      "Epoch [5/5], Step [280/625], Loss: 0.8040\n",
      "Epoch [5/5], Step [290/625], Loss: 0.7563\n",
      "Epoch [5/5], Step [300/625], Loss: 0.7204\n",
      "Epoch [5/5], Step [310/625], Loss: 0.6487\n",
      "Epoch [5/5], Step [320/625], Loss: 0.8147\n",
      "Epoch [5/5], Step [330/625], Loss: 0.7990\n",
      "Epoch [5/5], Step [340/625], Loss: 0.6810\n",
      "Epoch [5/5], Step [350/625], Loss: 0.8679\n",
      "Epoch [5/5], Step [360/625], Loss: 0.6585\n",
      "Epoch [5/5], Step [370/625], Loss: 0.8280\n",
      "Epoch [5/5], Step [380/625], Loss: 0.6529\n",
      "Epoch [5/5], Step [390/625], Loss: 0.7477\n",
      "Epoch [5/5], Step [400/625], Loss: 0.7270\n",
      "Epoch [5/5], Step [410/625], Loss: 0.8353\n",
      "Epoch [5/5], Step [420/625], Loss: 0.7542\n",
      "Epoch [5/5], Step [430/625], Loss: 0.6918\n",
      "Epoch [5/5], Step [440/625], Loss: 0.6688\n",
      "Epoch [5/5], Step [450/625], Loss: 0.7992\n",
      "Epoch [5/5], Step [460/625], Loss: 3.1148\n",
      "Epoch [5/5], Step [470/625], Loss: 1.8815\n",
      "Epoch [5/5], Step [480/625], Loss: 1.5190\n",
      "Epoch [5/5], Step [490/625], Loss: 1.2463\n",
      "Epoch [5/5], Step [500/625], Loss: 1.1427\n",
      "Epoch [5/5], Step [510/625], Loss: 1.1142\n",
      "Epoch [5/5], Step [520/625], Loss: 1.1399\n",
      "Epoch [5/5], Step [530/625], Loss: 1.2619\n",
      "Epoch [5/5], Step [540/625], Loss: 1.1299\n",
      "Epoch [5/5], Step [550/625], Loss: 1.2365\n",
      "Epoch [5/5], Step [560/625], Loss: 1.1611\n",
      "Epoch [5/5], Step [570/625], Loss: 1.1791\n",
      "Epoch [5/5], Step [580/625], Loss: 1.0509\n",
      "Epoch [5/5], Step [590/625], Loss: 1.0638\n",
      "Epoch [5/5], Step [600/625], Loss: 1.1312\n",
      "Epoch [5/5], Step [610/625], Loss: 1.0684\n",
      "Epoch [5/5], Step [620/625], Loss: 1.1234\n",
      "Epoch [5/5], Average Loss: 1.0381, Accuracy: 0.5225\n",
      "Class 0: Precision = 0.6793, Recall = 0.7282, F1 Score = 0.7029\n",
      "Class 1: Precision = 0.4343, Recall = 0.4822, F1 Score = 0.4570\n",
      "Class 2: Precision = 0.3742, Recall = 0.2296, F1 Score = 0.2846\n",
      "Class 3: Precision = 0.5398, Recall = 0.6500, F1 Score = 0.5898\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Constants\n",
    "NumPerElement = 5000  # Limit the number of samples to 100 per folder\n",
    "sequence_length = 3600  # The length of each sequence (number of time steps)\n",
    "input_size = 2  # Real and Imaginary components\n",
    "\n",
    "# Assuming you have 7 classes\n",
    "num_classes = 7\n",
    "hidden_size = 128  # Number of hidden units in LSTM\n",
    "\n",
    "# Folder paths and corresponding labels\n",
    "folders_and_labels = [\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/2CW', 0),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/4CW', 1),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/6CW', 2),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/8CW', 3),\n",
    "    # Add other folders here if needed\n",
    "]\n",
    "\n",
    "# Prepare data tensors\n",
    "im = torch.zeros(NumPerElement * len(folders_and_labels), sequence_length, input_size)  # (samples, time_steps, features)\n",
    "label = torch.zeros(NumPerElement * len(folders_and_labels))\n",
    "\n",
    "# Counters for the samples processed\n",
    "count = -1\n",
    "\n",
    "# Loop through each folder and load the data\n",
    "for folder_dir, folder_label in folders_and_labels:\n",
    "    count_in_folder = 0\n",
    "    for images in os.listdir(folder_dir):\n",
    "        if images != '.DS_Store' and count_in_folder < NumPerElement:\n",
    "            # Load the .mat file\n",
    "            AA = sio.loadmat(os.path.join(folder_dir, images))\n",
    "            count_in_folder += 1\n",
    "            count += 1\n",
    "            for key, value in AA.items():\n",
    "                # Store real and imaginary parts into the tensor\n",
    "                im[count, :, 0] = torch.from_numpy(value.real[0, :])  # Real part\n",
    "                im[count, :, 1] = torch.from_numpy(value.imag[0, :].copy())  # Imaginary part\n",
    "            label[count] = folder_label\n",
    "\n",
    "        if count_in_folder >= NumPerElement:  # Stop processing after 1000 files per folder\n",
    "            break\n",
    "\n",
    "# Verify the data shape and labels\n",
    "print(f\"Total samples loaded: {count + 1}\")\n",
    "print(f\"Labels for first few samples: {label[:10]}\")\n",
    "\n",
    "# Define the LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM expects input of shape (batch_size, sequence_length, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Only take the output from the last time step\n",
    "        last_hidden_state = lstm_out[:, -1, :]\n",
    "        out = self.fc(last_hidden_state)\n",
    "        return out\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the device\n",
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes).to(device)\n",
    "\n",
    "# Convert to dataset and DataLoader\n",
    "dataset = TensorDataset(im, label)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        # Move data and labels to the same device as the model\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels.long())  # Ensure labels are of type long for classification\n",
    "        total_loss += loss.item() * data.size(0)  # Accumulate loss (weighted by batch size)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Collect all predictions and labels for metrics\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        total_samples += data.size(0)\n",
    "\n",
    "        if (i+1) % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Convert all_preds and all_labels to numpy arrays\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Calculate Precision, Recall, F1 for each class\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average=None, labels=np.arange(num_classes))\n",
    "    recall = recall_score(all_labels, all_preds, average=None, labels=np.arange(num_classes))\n",
    "    f1 = f1_score(all_labels, all_preds, average=None, labels=np.arange(num_classes))\n",
    "\n",
    "    # Print the detailed metrics for each class\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss / total_samples:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i}: Precision = {precision[i]:.4f}, Recall = {recall[i]:.4f}, F1 Score = {f1[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896bdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2854bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301005ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c634fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8071e4a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 4000\n",
      "Labels for first few samples: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch [1/5], Step [10/125], Loss: 1.8712\n",
      "Epoch [1/5], Step [20/125], Loss: 1.5154\n",
      "Epoch [1/5], Step [30/125], Loss: 1.4510\n",
      "Epoch [1/5], Step [40/125], Loss: 1.4151\n",
      "Epoch [1/5], Step [50/125], Loss: 1.3767\n",
      "Epoch [1/5], Step [60/125], Loss: 1.4039\n",
      "Epoch [1/5], Step [70/125], Loss: 1.3824\n",
      "Epoch [1/5], Step [80/125], Loss: 1.4106\n",
      "Epoch [1/5], Step [90/125], Loss: 1.4193\n",
      "Epoch [1/5], Step [100/125], Loss: 1.3418\n",
      "Epoch [1/5], Step [110/125], Loss: 1.3882\n",
      "Epoch [1/5], Step [120/125], Loss: 1.3744\n",
      "Epoch [1/5], Average Loss: 1.4672, Accuracy: 0.2507\n",
      "Class 0: Precision = 0.2382, Recall = 0.1510, F1 Score = 0.1848\n",
      "Class 1: Precision = 0.2457, Recall = 0.2000, F1 Score = 0.2205\n",
      "Class 2: Precision = 0.2460, Recall = 0.4030, F1 Score = 0.3055\n",
      "Class 3: Precision = 0.2724, Recall = 0.2490, F1 Score = 0.2602\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [2/5], Step [10/125], Loss: 1.3899\n",
      "Epoch [2/5], Step [20/125], Loss: 1.3975\n",
      "Epoch [2/5], Step [30/125], Loss: 1.4003\n",
      "Epoch [2/5], Step [40/125], Loss: 1.3727\n",
      "Epoch [2/5], Step [50/125], Loss: 1.3906\n",
      "Epoch [2/5], Step [60/125], Loss: 1.3933\n",
      "Epoch [2/5], Step [70/125], Loss: 1.4506\n",
      "Epoch [2/5], Step [80/125], Loss: 1.3909\n",
      "Epoch [2/5], Step [90/125], Loss: 1.3762\n",
      "Epoch [2/5], Step [100/125], Loss: 1.3497\n",
      "Epoch [2/5], Step [110/125], Loss: 1.3862\n",
      "Epoch [2/5], Step [120/125], Loss: 1.3806\n",
      "Epoch [2/5], Average Loss: 1.3941, Accuracy: 0.2465\n",
      "Class 0: Precision = 0.2398, Recall = 0.2300, F1 Score = 0.2348\n",
      "Class 1: Precision = 0.2435, Recall = 0.4010, F1 Score = 0.3030\n",
      "Class 2: Precision = 0.2504, Recall = 0.1540, F1 Score = 0.1907\n",
      "Class 3: Precision = 0.2580, Recall = 0.2010, F1 Score = 0.2260\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [3/5], Step [10/125], Loss: 1.4271\n",
      "Epoch [3/5], Step [20/125], Loss: 1.3828\n",
      "Epoch [3/5], Step [30/125], Loss: 1.3987\n",
      "Epoch [3/5], Step [40/125], Loss: 1.3775\n",
      "Epoch [3/5], Step [50/125], Loss: 1.4217\n",
      "Epoch [3/5], Step [60/125], Loss: 1.3750\n",
      "Epoch [3/5], Step [70/125], Loss: 1.3843\n",
      "Epoch [3/5], Step [80/125], Loss: 1.3774\n",
      "Epoch [3/5], Step [90/125], Loss: 1.3817\n",
      "Epoch [3/5], Step [100/125], Loss: 1.3546\n",
      "Epoch [3/5], Step [110/125], Loss: 1.4020\n",
      "Epoch [3/5], Step [120/125], Loss: 1.3386\n",
      "Epoch [3/5], Average Loss: 1.3931, Accuracy: 0.2440\n",
      "Class 0: Precision = 0.2329, Recall = 0.1020, F1 Score = 0.1419\n",
      "Class 1: Precision = 0.2236, Recall = 0.2120, F1 Score = 0.2177\n",
      "Class 2: Precision = 0.2535, Recall = 0.3580, F1 Score = 0.2968\n",
      "Class 3: Precision = 0.2529, Recall = 0.3040, F1 Score = 0.2761\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [4/5], Step [10/125], Loss: 1.5036\n",
      "Epoch [4/5], Step [20/125], Loss: 1.4284\n",
      "Epoch [4/5], Step [30/125], Loss: 1.4260\n",
      "Epoch [4/5], Step [40/125], Loss: 1.3698\n",
      "Epoch [4/5], Step [50/125], Loss: 1.3615\n",
      "Epoch [4/5], Step [60/125], Loss: 1.3943\n",
      "Epoch [4/5], Step [70/125], Loss: 1.3626\n",
      "Epoch [4/5], Step [80/125], Loss: 1.3834\n",
      "Epoch [4/5], Step [90/125], Loss: 1.3773\n",
      "Epoch [4/5], Step [100/125], Loss: 1.3832\n",
      "Epoch [4/5], Step [110/125], Loss: 1.3817\n",
      "Epoch [4/5], Step [120/125], Loss: 1.4121\n",
      "Epoch [4/5], Average Loss: 1.3927, Accuracy: 0.2572\n",
      "Class 0: Precision = 0.2933, Recall = 0.2690, F1 Score = 0.2806\n",
      "Class 1: Precision = 0.2335, Recall = 0.2120, F1 Score = 0.2222\n",
      "Class 2: Precision = 0.2461, Recall = 0.2340, F1 Score = 0.2399\n",
      "Class 3: Precision = 0.2565, Recall = 0.3140, F1 Score = 0.2824\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [5/5], Step [10/125], Loss: 1.2838\n",
      "Epoch [5/5], Step [20/125], Loss: 1.4773\n",
      "Epoch [5/5], Step [30/125], Loss: 1.3779\n",
      "Epoch [5/5], Step [40/125], Loss: 1.3657\n",
      "Epoch [5/5], Step [50/125], Loss: 1.3648\n",
      "Epoch [5/5], Step [60/125], Loss: 1.3676\n",
      "Epoch [5/5], Step [70/125], Loss: 1.3863\n",
      "Epoch [5/5], Step [80/125], Loss: 1.4174\n",
      "Epoch [5/5], Step [90/125], Loss: 1.3675\n",
      "Epoch [5/5], Step [100/125], Loss: 1.3054\n",
      "Epoch [5/5], Step [110/125], Loss: 1.5088\n",
      "Epoch [5/5], Step [120/125], Loss: 1.4043\n",
      "Epoch [5/5], Average Loss: 1.3855, Accuracy: 0.2710\n",
      "Class 0: Precision = 0.2948, Recall = 0.3160, F1 Score = 0.3050\n",
      "Class 1: Precision = 0.2315, Recall = 0.2220, F1 Score = 0.2266\n",
      "Class 2: Precision = 0.2541, Recall = 0.2500, F1 Score = 0.2520\n",
      "Class 3: Precision = 0.3005, Recall = 0.2960, F1 Score = 0.2982\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Constants\n",
    "NumPerElement = 1000  # Limit the number of samples to 100 per folder\n",
    "sequence_length = 3600  # The length of each sequence (number of time steps)\n",
    "input_size = 2  # Real and Imaginary components\n",
    "\n",
    "# Assuming you have 7 classes\n",
    "num_classes = 7\n",
    "hidden_size = 128  # Number of hidden units in LSTM\n",
    "\n",
    "# Folder paths and corresponding labels\n",
    "folders_and_labels = [\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/2CW', 0),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/4CW', 1),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/6CW', 2),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/8CW', 3),\n",
    "    # Add other folders here if needed\n",
    "]\n",
    "\n",
    "# Prepare data tensors\n",
    "im = torch.zeros(NumPerElement * len(folders_and_labels), sequence_length, input_size)  # (samples, time_steps, features)\n",
    "label = torch.zeros(NumPerElement * len(folders_and_labels))\n",
    "\n",
    "# Counters for the samples processed\n",
    "count = -1\n",
    "\n",
    "# Loop through each folder and load the data\n",
    "for folder_dir, folder_label in folders_and_labels:\n",
    "    count_in_folder = 0\n",
    "    for images in os.listdir(folder_dir):\n",
    "        if images != '.DS_Store' and count_in_folder < NumPerElement:\n",
    "            # Load the .mat file\n",
    "            AA = sio.loadmat(os.path.join(folder_dir, images))\n",
    "            count_in_folder += 1\n",
    "            count += 1\n",
    "            for key, value in AA.items():\n",
    "                # Store real and imaginary parts into the tensor\n",
    "                im[count, :, 0] = torch.from_numpy(value.real[0, :])  # Real part\n",
    "                im[count, :, 1] = torch.from_numpy(value.imag[0, :].copy())  # Imaginary part\n",
    "            label[count] = folder_label\n",
    "\n",
    "        if count_in_folder >= NumPerElement:  # Stop processing after 1000 files per folder\n",
    "            break\n",
    "\n",
    "# Verify the data shape and labels\n",
    "print(f\"Total samples loaded: {count + 1}\")\n",
    "print(f\"Labels for first few samples: {label[:10]}\")\n",
    "\n",
    "# Define the LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM expects input of shape (batch_size, sequence_length, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Only take the output from the last time step\n",
    "        last_hidden_state = lstm_out[:, -1, :]\n",
    "        out = self.fc(last_hidden_state)\n",
    "        return out\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the device\n",
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes).to(device)\n",
    "\n",
    "# Convert to dataset and DataLoader\n",
    "dataset = TensorDataset(im, label)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        # Move data and labels to the same device as the model\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels.long())  # Ensure labels are of type long for classification\n",
    "        total_loss += loss.item() * data.size(0)  # Accumulate loss (weighted by batch size)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Collect all predictions and labels for metrics\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        total_samples += data.size(0)\n",
    "\n",
    "        if (i+1) % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Convert all_preds and all_labels to numpy arrays\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Calculate Precision, Recall, F1 for each class, with zero_division set to 0\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "\n",
    "    # Print the detailed metrics for each class\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss / total_samples:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i}: Precision = {precision[i]:.4f}, Recall = {recall[i]:.4f}, F1 Score = {f1[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300d01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ad3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ba3aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: /Users/anuraagthakur/Desktop/RawData/2CW, Label: 0\n",
      "Assigned label 0 to sample 1 in folder /Users/anuraagthakur/Desktop/RawData/2CW\n",
      "Assigned label 0 to sample 2 in folder /Users/anuraagthakur/Desktop/RawData/2CW\n",
      "Assigned label 0 to sample 3 in folder /Users/anuraagthakur/Desktop/RawData/2CW\n",
      "Assigned label 0 to sample 4 in folder /Users/anuraagthakur/Desktop/RawData/2CW\n",
      "Assigned label 0 to sample 5 in folder /Users/anuraagthakur/Desktop/RawData/2CW\n",
      "Processing folder: /Users/anuraagthakur/Desktop/RawData/4CW, Label: 1\n",
      "Assigned label 1 to sample 1 in folder /Users/anuraagthakur/Desktop/RawData/4CW\n",
      "Assigned label 1 to sample 2 in folder /Users/anuraagthakur/Desktop/RawData/4CW\n",
      "Assigned label 1 to sample 3 in folder /Users/anuraagthakur/Desktop/RawData/4CW\n",
      "Assigned label 1 to sample 4 in folder /Users/anuraagthakur/Desktop/RawData/4CW\n",
      "Assigned label 1 to sample 5 in folder /Users/anuraagthakur/Desktop/RawData/4CW\n",
      "Processing folder: /Users/anuraagthakur/Desktop/RawData/6CW, Label: 2\n",
      "Assigned label 2 to sample 1 in folder /Users/anuraagthakur/Desktop/RawData/6CW\n",
      "Assigned label 2 to sample 2 in folder /Users/anuraagthakur/Desktop/RawData/6CW\n",
      "Assigned label 2 to sample 3 in folder /Users/anuraagthakur/Desktop/RawData/6CW\n",
      "Assigned label 2 to sample 4 in folder /Users/anuraagthakur/Desktop/RawData/6CW\n",
      "Assigned label 2 to sample 5 in folder /Users/anuraagthakur/Desktop/RawData/6CW\n",
      "Processing folder: /Users/anuraagthakur/Desktop/RawData/8CW, Label: 3\n",
      "Assigned label 3 to sample 1 in folder /Users/anuraagthakur/Desktop/RawData/8CW\n",
      "Assigned label 3 to sample 2 in folder /Users/anuraagthakur/Desktop/RawData/8CW\n",
      "Assigned label 3 to sample 3 in folder /Users/anuraagthakur/Desktop/RawData/8CW\n",
      "Assigned label 3 to sample 4 in folder /Users/anuraagthakur/Desktop/RawData/8CW\n",
      "Assigned label 3 to sample 5 in folder /Users/anuraagthakur/Desktop/RawData/8CW\n",
      "Total samples loaded: 100\n",
      "Labels for first few samples: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch [1/5], Average Loss: 1.9341, Accuracy: 0.2500\n",
      "Class 0: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 1: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 2: Precision = 0.2500, Recall = 1.0000, F1 Score = 0.4000\n",
      "Class 3: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [2/5], Average Loss: 1.8904, Accuracy: 0.2500\n",
      "Class 0: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 1: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 2: Precision = 0.2500, Recall = 1.0000, F1 Score = 0.4000\n",
      "Class 3: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [3/5], Average Loss: 1.8352, Accuracy: 0.2500\n",
      "Class 0: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 1: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 2: Precision = 0.2500, Recall = 1.0000, F1 Score = 0.4000\n",
      "Class 3: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [4/5], Average Loss: 1.7309, Accuracy: 0.2500\n",
      "Class 0: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 1: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 2: Precision = 0.2500, Recall = 1.0000, F1 Score = 0.4000\n",
      "Class 3: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Epoch [5/5], Average Loss: 1.4680, Accuracy: 0.2500\n",
      "Class 0: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 1: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 2: Precision = 0.2500, Recall = 1.0000, F1 Score = 0.4000\n",
      "Class 3: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 5: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
      "Class 6: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Constants\n",
    "NumPerElement = 25  # Limit the number of samples to 100 per folder\n",
    "sequence_length = 3600  # The length of each sequence (number of time steps)\n",
    "input_size = 2  # Real and Imaginary components\n",
    "\n",
    "# Assuming you have 7 classes\n",
    "num_classes = 7\n",
    "hidden_size = 128  # Number of hidden units in LSTM\n",
    "\n",
    "# Folder paths and corresponding labels\n",
    "folders_and_labels = [\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/2CW', 0),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/4CW', 1),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/6CW', 2),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/8CW', 3),\n",
    "    # Add other folders here if needed\n",
    "]\n",
    "\n",
    "# Prepare data tensors\n",
    "im = torch.zeros(NumPerElement * len(folders_and_labels), sequence_length, input_size)  # (samples, time_steps, features)\n",
    "label = torch.zeros(NumPerElement * len(folders_and_labels))\n",
    "\n",
    "# Counters for the samples processed\n",
    "count = -1\n",
    "\n",
    "# Loop through each folder and load the data\n",
    "for folder_dir, folder_label in folders_and_labels:\n",
    "    count_in_folder = 0\n",
    "    print(f\"Processing folder: {folder_dir}, Label: {folder_label}\")  # Debugging print\n",
    "    for images in os.listdir(folder_dir):\n",
    "        if images != '.DS_Store' and count_in_folder < NumPerElement:\n",
    "            # Load the .mat file\n",
    "            AA = sio.loadmat(os.path.join(folder_dir, images))\n",
    "            count_in_folder += 1\n",
    "            count += 1\n",
    "            for key, value in AA.items():\n",
    "                # Store real and imaginary parts into the tensor\n",
    "                im[count, :, 0] = torch.from_numpy(value.real[0, :])  # Real part\n",
    "                im[count, :, 1] = torch.from_numpy(value.imag[0, :].copy())  # Imaginary part\n",
    "            label[count] = folder_label\n",
    "\n",
    "            # Debugging: Print label assignment for the current sample\n",
    "            if count_in_folder <= 5:  # Print the first few samples for verification\n",
    "                print(f\"Assigned label {folder_label} to sample {count_in_folder} in folder {folder_dir}\")\n",
    "\n",
    "        if count_in_folder >= NumPerElement:  # Stop processing after 5000 files per folder\n",
    "            break\n",
    "\n",
    "# Verify the data shape and labels\n",
    "print(f\"Total samples loaded: {count + 1}\")\n",
    "print(f\"Labels for first few samples: {label[:10]}\")\n",
    "\n",
    "# Define the LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM expects input of shape (batch_size, sequence_length, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Only take the output from the last time step\n",
    "        last_hidden_state = lstm_out[:, -1, :]\n",
    "        out = self.fc(last_hidden_state)\n",
    "        return out\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the device\n",
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes).to(device)\n",
    "\n",
    "# Convert to dataset and DataLoader\n",
    "dataset = TensorDataset(im, label)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        # Move data and labels to the same device as the model\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels.long())  # Ensure labels are of type long for classification\n",
    "        total_loss += loss.item() * data.size(0)  # Accumulate loss (weighted by batch size)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Collect all predictions and labels for metrics\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        total_samples += data.size(0)\n",
    "\n",
    "        if (i+1) % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Convert all_preds and all_labels to numpy arrays\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Calculate Precision, Recall, F1 for each class, with zero_division set to 0\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "\n",
    "    # Print the detailed metrics for each class\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss / total_samples:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i}: Precision = {precision[i]:.4f}, Recall = {recall[i]:.4f}, F1 Score = {f1[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c7d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67fbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec01fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d82137d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 4000\n",
      "Labels for first few samples: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch [1/5], Step [10/125], Loss: 1.3981\n",
      "Epoch [1/5], Step [20/125], Loss: 1.3902\n",
      "Epoch [1/5], Step [30/125], Loss: 1.3783\n",
      "Epoch [1/5], Step [40/125], Loss: 1.3877\n",
      "Epoch [1/5], Step [50/125], Loss: 1.3888\n",
      "Epoch [1/5], Step [60/125], Loss: 1.3752\n",
      "Epoch [1/5], Step [70/125], Loss: 1.3480\n",
      "Epoch [1/5], Step [80/125], Loss: 1.3516\n",
      "Epoch [1/5], Step [90/125], Loss: 1.1711\n",
      "Epoch [1/5], Step [100/125], Loss: 1.2562\n",
      "Epoch [1/5], Step [110/125], Loss: 1.1675\n",
      "Epoch [1/5], Step [120/125], Loss: 0.9899\n",
      "Epoch [1/5], Average Loss: 1.3070, Accuracy: 0.3272\n",
      "Class 0: Precision = 0.3750, Recall = 0.4890, F1 Score = 0.4245\n",
      "Class 1: Precision = 0.2746, Recall = 0.1590, F1 Score = 0.2014\n",
      "Class 2: Precision = 0.3659, Recall = 0.1200, F1 Score = 0.1807\n",
      "Class 3: Precision = 0.3024, Recall = 0.5410, F1 Score = 0.3880\n",
      "Epoch [2/5], Step [10/125], Loss: 1.2135\n",
      "Epoch [2/5], Step [20/125], Loss: 1.2254\n",
      "Epoch [2/5], Step [30/125], Loss: 1.3323\n",
      "Epoch [2/5], Step [40/125], Loss: 1.3728\n",
      "Epoch [2/5], Step [50/125], Loss: 1.3007\n",
      "Epoch [2/5], Step [60/125], Loss: 1.3838\n",
      "Epoch [2/5], Step [70/125], Loss: 1.1976\n",
      "Epoch [2/5], Step [80/125], Loss: 0.9231\n",
      "Epoch [2/5], Step [90/125], Loss: 0.9939\n",
      "Epoch [2/5], Step [100/125], Loss: 1.1519\n",
      "Epoch [2/5], Step [110/125], Loss: 1.2824\n",
      "Epoch [2/5], Step [120/125], Loss: 1.0735\n",
      "Epoch [2/5], Average Loss: 1.1939, Accuracy: 0.4333\n",
      "Class 0: Precision = 0.4302, Recall = 0.6010, F1 Score = 0.5015\n",
      "Class 1: Precision = 0.3151, Recall = 0.3110, F1 Score = 0.3130\n",
      "Class 2: Precision = 0.3485, Recall = 0.3530, F1 Score = 0.3507\n",
      "Class 3: Precision = 0.7761, Recall = 0.4680, F1 Score = 0.5839\n",
      "Epoch [3/5], Step [10/125], Loss: 1.0709\n",
      "Epoch [3/5], Step [20/125], Loss: 1.0337\n",
      "Epoch [3/5], Step [30/125], Loss: 1.2296\n",
      "Epoch [3/5], Step [40/125], Loss: 1.1510\n",
      "Epoch [3/5], Step [50/125], Loss: 1.2957\n",
      "Epoch [3/5], Step [60/125], Loss: 1.1033\n",
      "Epoch [3/5], Step [70/125], Loss: 0.9139\n",
      "Epoch [3/5], Step [80/125], Loss: 1.2904\n",
      "Epoch [3/5], Step [90/125], Loss: 1.2400\n",
      "Epoch [3/5], Step [100/125], Loss: 1.1866\n",
      "Epoch [3/5], Step [110/125], Loss: 1.2542\n",
      "Epoch [3/5], Step [120/125], Loss: 1.0419\n",
      "Epoch [3/5], Average Loss: 1.1515, Accuracy: 0.4755\n",
      "Class 0: Precision = 0.7147, Recall = 0.5260, F1 Score = 0.6060\n",
      "Class 1: Precision = 0.3477, Recall = 0.3380, F1 Score = 0.3428\n",
      "Class 2: Precision = 0.3720, Recall = 0.2980, F1 Score = 0.3309\n",
      "Class 3: Precision = 0.4963, Recall = 0.7400, F1 Score = 0.5941\n",
      "Epoch [4/5], Step [10/125], Loss: 1.3134\n",
      "Epoch [4/5], Step [20/125], Loss: 1.3472\n",
      "Epoch [4/5], Step [30/125], Loss: 1.3410\n",
      "Epoch [4/5], Step [40/125], Loss: 1.3413\n",
      "Epoch [4/5], Step [50/125], Loss: 1.2248\n",
      "Epoch [4/5], Step [60/125], Loss: 1.4041\n",
      "Epoch [4/5], Step [70/125], Loss: 1.2689\n",
      "Epoch [4/5], Step [80/125], Loss: 1.2341\n",
      "Epoch [4/5], Step [90/125], Loss: 1.3622\n",
      "Epoch [4/5], Step [100/125], Loss: 1.3337\n",
      "Epoch [4/5], Step [110/125], Loss: 1.2902\n",
      "Epoch [4/5], Step [120/125], Loss: 1.3184\n",
      "Epoch [4/5], Average Loss: 1.3064, Accuracy: 0.3305\n",
      "Class 0: Precision = 0.9252, Recall = 0.2350, F1 Score = 0.3748\n",
      "Class 1: Precision = 0.2715, Recall = 0.3160, F1 Score = 0.2921\n",
      "Class 2: Precision = 0.2732, Recall = 0.3890, F1 Score = 0.3210\n",
      "Class 3: Precision = 0.3299, Recall = 0.3820, F1 Score = 0.3540\n",
      "Epoch [5/5], Step [10/125], Loss: 1.3565\n",
      "Epoch [5/5], Step [20/125], Loss: 1.3287\n",
      "Epoch [5/5], Step [30/125], Loss: 1.3680\n",
      "Epoch [5/5], Step [40/125], Loss: 1.3758\n",
      "Epoch [5/5], Step [50/125], Loss: 1.2967\n",
      "Epoch [5/5], Step [60/125], Loss: 1.2698\n",
      "Epoch [5/5], Step [70/125], Loss: 1.3261\n",
      "Epoch [5/5], Step [80/125], Loss: 1.3212\n",
      "Epoch [5/5], Step [90/125], Loss: 1.4073\n",
      "Epoch [5/5], Step [100/125], Loss: 1.3260\n",
      "Epoch [5/5], Step [110/125], Loss: 1.3358\n",
      "Epoch [5/5], Step [120/125], Loss: 1.3099\n",
      "Epoch [5/5], Average Loss: 1.3206, Accuracy: 0.2935\n",
      "Class 0: Precision = 0.9156, Recall = 0.2170, F1 Score = 0.3508\n",
      "Class 1: Precision = 0.1667, Recall = 0.0070, F1 Score = 0.0134\n",
      "Class 2: Precision = 0.2410, Recall = 0.3630, F1 Score = 0.2897\n",
      "Class 3: Precision = 0.2650, Recall = 0.5870, F1 Score = 0.3652\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Constants\n",
    "NumPerElement = 1000  # Limit the number of samples to 10 per folder (for testing)\n",
    "sequence_length = 3600  # The length of each sequence (number of time steps)\n",
    "\n",
    "input_size = 2  # Real and Imaginary components\n",
    "hidden_size = 128  # Number of hidden units per LSTM layer\n",
    "num_classes = 4  # Number of output classes\n",
    "num_layers = 3  # Number of stacked LSTM layers\n",
    "\n",
    "\n",
    "# Folder paths and corresponding labels\n",
    "folders_and_labels = [\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/2CW', 0),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/4CW', 1),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/6CW', 2),\n",
    "    ('/Users/anuraagthakur/Desktop/RawData/8CW', 3),\n",
    "    # Add other folders here if needed\n",
    "]\n",
    "\n",
    "# Prepare data tensors\n",
    "im = torch.zeros(NumPerElement * len(folders_and_labels), sequence_length, input_size)  # (samples, time_steps, features)\n",
    "label = torch.zeros(NumPerElement * len(folders_and_labels))\n",
    "\n",
    "# Counters for the samples processed\n",
    "count = -1\n",
    "\n",
    "# Loop through each folder and load the data\n",
    "for folder_dir, folder_label in folders_and_labels:\n",
    "    count_in_folder = 0\n",
    "    for images in os.listdir(folder_dir):\n",
    "        if images != '.DS_Store' and count_in_folder < NumPerElement:\n",
    "            # Load the .mat file\n",
    "            AA = sio.loadmat(os.path.join(folder_dir, images))\n",
    "            count_in_folder += 1\n",
    "            count += 1\n",
    "            for key, value in AA.items():\n",
    "                # Store real and imaginary parts into the tensor\n",
    "                im[count, :, 0] = torch.from_numpy(value.real[0, :])  # Real part\n",
    "                im[count, :, 1] = torch.from_numpy(value.imag[0, :].copy())  # Imaginary part\n",
    "            label[count] = folder_label\n",
    "\n",
    "        if count_in_folder >= NumPerElement:  # Stop processing after 10 files per folder\n",
    "            break\n",
    "\n",
    "# Verify the data shape and labels\n",
    "print(f\"Total samples loaded: {count + 1}\")\n",
    "print(f\"Labels for first few samples: {label[:10]}\")\n",
    "\n",
    "# Define the Sequential LSTM Model\n",
    "model = nn.Sequential(\n",
    "    nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True),  # Stacked LSTM layers without dropout\n",
    "    nn.Linear(hidden_size, num_classes)  # Fully connected layer for classification\n",
    ")\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Convert to dataset and DataLoader\n",
    "dataset = TensorDataset(im, label)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        # Move data and labels to the same device as the model\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        lstm_out, _ = model[0](data)  # Only pass through LSTM layer\n",
    "        outputs = model[1](lstm_out[:, -1, :])  # Use output from last time step (last hidden state)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels.long())  # Ensure labels are of type long for classification\n",
    "        total_loss += loss.item() * data.size(0)  # Accumulate loss (weighted by batch size)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Collect all predictions and labels for metrics\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        total_samples += data.size(0)\n",
    "\n",
    "        if (i+1) % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Convert all_preds and all_labels to numpy arrays\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Calculate Precision, Recall, F1 for each class, with zero_division set to 0\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "\n",
    "    # Print the detailed metrics for each class\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss / total_samples:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i}: Precision = {precision[i]:.4f}, Recall = {recall[i]:.4f}, F1 Score = {f1[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906de28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
